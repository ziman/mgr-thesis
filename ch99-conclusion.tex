\chapter{Discussion}

\section{Further work}

There are \emph{lots} of things in this development that could be improved and many alternatives
to the design choices of ours that could be interesting to explore further.

In \Fref{sec:forks}, we mentioned the transactionality of exceptions in pure code. Transforming
linear code to the form of ``forks'' mentioned there is not too hard -- although not trivial
-- and this
intermediate representation could provide a reasoning bridge between tree-structured expressions
and linear code. The compiler could even emit this intermediate structure first,
linearizing it later, which might facilitate proving the part of correspondence between ``forks''
and linear code. Such an intermediate structure might then be useful in proving termination and
correctness of the program.

There are other models that could help proving the desired properties. In
\Fref{sec:handler-frames}, we introduced the notion of handler frames that correspond to
catch-expressions. However, this notion can be generalized to all other types of expressions,
yielding \emph{expression frames}: any expression, not only instances of the constructor
\ident{Catch} corresponds to a frame similar to the one in \Fref{fig:stack-frames}.
A suitable model of expression frames could be another intermediate structure that may
be useful in proving termination and correctness.

Instead of structural recursion on the code sequence, a~decreasing measure
could be used. This would enable arbitrary jumping within the code and execution on
the virtual machine could be modeled very closely to how real machines work.

The high-level language could be extended by functions or lambdas. Besides higher expressivity
of regular code, this would enable exception handlers to inspect exceptions and behave differently
in different cases. This also means that it would make sense to throw values and the syntax
of the throw-expressions would be extended to include the value to be thrown.
Finally, once values are added to \ident{throw}, type-based selection of handlers could be
implemented.

On the other hand, the high-level language could be made to support just one type: numbers.
This would bring some simplification to the Agda code -- stack shapes would be replaced by
simple stack sizes -- and perhaps help resolve termination
in the cases where we were unable to prove it. Usability of this approach depends on the
requirements; if all that is needed are numbers, generalization to other data types makes
the code unnecessarily complicated and this simplification would pay off.

In \Fref{sec:lin-correctness} we mention that the operator lemma in the proof of correctness
must contain as much as 12 (trivial) clauses per operator. A suitable factorization of the
lemma into smaller functions might reduce this constant; employing some automation technique
might remove it altogether.

Unfortunately, our structurally recursive model of execution cannot include jumps, which are an
important part of functionality of real-world machines. The paper by Hutton and Wright
\cite{gmh:exceptions} uses labels to mark locations in code that may be jumped to. Although
we cannot jump, it might be useful to add labels and prove that jumping to them is
equivalent with our mode-switching execution strategy. This would make translation
of our algorithm to real-world implementations easier and more obvious.

\section{Related work}

Besides the paper about \emph{verification} of a compiler of exceptions
\cite{gmh:exceptions}, later formalized by Nipkow \cite{nipkow}, Hutton and Wright also published a
paper that \emph{calculates} a virtual machine from the same high-level language with exceptions
via defunctionalization \cite{gmh:exceptional-machine}.

McKinna and Wright created a certified compiler of expressions \cite{epigram-compiler} in Epigram.
Their compiler does not have exceptions but it features numeric and Boolean types and
conditions from the beginning. Their development also makes heavy use of dependent typing,
which makes their approach very close to ours in this respect.

Chlipala presents a ``verified compiler for an impure functional language'' \cite{chlipala10},
implemented in Coq, trying to assess what ways might be viable to write a real-world certified
compiler. Besides other features, the impure functional language also includes
exceptions. The compiler is quite elaborate and consists of multiple stages, including
an optimization stage. The development makes extensive use of the Coq
tactic language to automate proofs, and PHOAS%
\footnote{Parametric higher-order abstract syntax \cite{chlipala08}.} to deal with binders,
in the effort to save as much work as possible when both implementing and extending
the compiler. The paper does not discuss execution of the resulting code on a virtual machine
and does not deal with termination of the execution function.

Leroy presents a verified realistic compiler of (a substantial subset of) the C programming language,
named CompCert \cite{leroy09}, also written and verified in Coq. This is a full-featured real-world
compiler of a mainstream procedural language to PowerPC machine code, dealing with advanced topics
like optimizations and register allocation in a completely certified way, while keeping
the performance of the emitted code on par with that of the mainstream C compilers. Being a C
compiler, it does not support exceptions.

\section{Conclusions}

Finally, we converged to a solution that meets our objectives: a certified compiler for a
language with exceptions, along with a tail-recursive executable interpreter of the corresponding
low-level code. While we have diverged from the
paper by Hutton and Wright \cite{gmh:exceptions} in low-level execution-related matters
by using different machine modes for instruction skipping instead of jumping, the overall
direction of our development happens to match that of the paper, while adding
structurality everywhere.

We use the power of dependent types to keep relatively strong invariants; as a~consequence,
we needn't bother with cases that are impossible, such as executing the instruction \ident{ADD}
on an empty stack. We set up the types so that they rule out all such cases, which would be
impossible in languages with weaker type systems, such as Haskell or OCaml.

However, this did not take too much work, when compared to such languages.
Type signatures are a bit more elaborate but the code itself is very similar. The whole Agda
development is 210 lines of code, and 120 lines of proofs, all inclusive.

When we look at the objectives listed in the Introduction on page \pageref{objectives},
we can conclude that they have been met.
\begin{itemize}
	\item Our program is \emph{runnable}; it is structurally recursive,
		obviously terminating, and provably correct with respect to the presented
		specification.
		
	\item The code is \emph{readable}. Especially because all recursion is structural,
		there are no proof terms in the
		informative part of the development. The small-step operational semantics
		of individual instructions is given clearly by the tabular form of the function
		\ident{execInstr} (\Fref{sec:lin-instr-semantics}). And, as already mentioned,
		also the rest of code looks similarly to what the counterparts in other functional
		languages would look like.
		
	\item The low-level code is simple enough to be \emph{executable by a stack machine}.
		Except for a small and limited amount of state, we do not use anything more,
		especially not implicit stacks, nor arbitrarily-sized instructions.
		
	\item \emph{Extraction of code} to other languages should also be simple, mostly due to
		the properties that make the code readable; in particular, due to the absence of
		of proof terms in the informative/executable part of the development, which follows
		from structurality of the recursion used, and due to the similarity to what
		the program would look like in other functional languages.
\end{itemize}

It has been 45 years since the seminal paper by McCarthy and Painter \cite{mccarthy67}
opened up the door into the world of verified compilers by introducing the first formally
verified compiler. In the meantime, many things have changed, theory has been developed and
machines have become more powerful, able to not even check our proofs but also assist us
in writing them. To fully reap the power of the machines in this area, we need to develop
efficient methods of formal verification -- and while lots of ingenious work has been
done in this area, it is still a long and exciting way to go. Let this thesis be a small
step towards this goal.

\begin{comment}

Some further work.

\todo{What we have achieved, how the objectives have been met.}

%\todo{Hyperdependent code}

%\todo{Peirce (statically \emph{bound} exceptions)}

\todo{How should the attached code be structured and referenced from the thesis? Insert references in all appropriate places.}

%\todo{C++ has a superhandler that aborts if an uncaught exception occurs.}

\todo{Mention Type Theory?}

\todo{Add references to the source code.}

\todo{Change ! to $\times$ and vice versa.}

\todo{Add non-breaking spaces}

\todo{Spell-check}

\todo{Search for \texttt{\textbackslash def \textbackslash @textbottom\{\textbackslash vskip
\textbackslash z@ \textbackslash@plus 14pt\}} in the headers and decrease those 14 pts to
something sane when everything is done.}

\todo{Consider wording: data type vs. type family. Simple or precise?}

\todo{Proper italics in bibliography. Proper ISO bibliography.}

\todo{Proper typography, capitalization, grammar in bibliography.}

\end{comment}
